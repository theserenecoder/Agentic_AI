{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f65c94",
   "metadata": {},
   "source": [
    "### FAISS\n",
    "\n",
    "Facebook AI Similarity Search is used for effective similarity search and clusterring of dense vector. It's algo searches in sets of vectors of any size. It is completely written in C++ with wrappers for Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b857e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4671d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashut\\OneDrive\\Documents\\study material\\Agentic_AI_Krish\\Agentic_AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc0828",
   "metadata": {},
   "source": [
    "### Similarity Search\n",
    "\n",
    "Given a set of vectors $x_i$ in dimension $d$, Faiss builds a data structure in RAM from it. Once the structure is constructed, and a new given vector $x$ in dimension $d$ it performs efficiently the operation:\n",
    "$j = argmin_i||x-x_i||$\n",
    "\n",
    "where ||.|| is the Eucliden distance ($L^2$).\n",
    "\n",
    "In FAISS data structure is an index, an object that has an add method to add $x_i$ vectors. Computing the argmin is the search algorithm on the index.\n",
    "\n",
    "FAISS can also:\n",
    "- Return $k^th$ nearest neighbours.\n",
    "- Search several vectors at a time (batch processing).\n",
    "- Trade precision for speed.\n",
    "- Performe maximum inner product search $argmax_i(x,x_i)$ instead of minimum Euclidean search. Limited support for other distances.\n",
    "- Store the index on disk rather than RAM.\n",
    "- Index binary vectors rather than floating point vectors.\n",
    "\n",
    "Mostly Used Similarity Search are:\n",
    "\n",
    "- Cosin Similarity\n",
    "- Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "befd27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "documents = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The dog chased the cat.\",\n",
    "    \"Cats and dogs are both popular pets.\",\n",
    "    \"I love my pet cat.\",\n",
    "    \"Dogs are great companions.\"\n",
    "] \n",
    "\n",
    "my_qestion = \"What do cats and dogs have in common?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b995cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20420025, 0.28294987, 0.69093253, 0.45672216, 0.57053787]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embed=embeddings.embed_documents(documents)\n",
    "query_embed = embeddings.embed_query(my_qestion)\n",
    "cosine_similarity([query_embed], doc_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0f7faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.26158608, 1.19753927, 0.78621559, 1.04237982, 0.92678164]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "euclidean_distances([query_embed], doc_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21afe27",
   "metadata": {},
   "source": [
    "### FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa7ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff83dc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x000001EE47720DE0> >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a FAISS index\n",
    "## The FAISS index is used to store and search the embeddings.\n",
    "index = faiss.IndexFlatL2(768)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43b9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a new FAISS vector store\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37d49bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is cat and dog'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add documents to the FAISS index\n",
    "data = ['This is cat', 'This is dog', 'This is cat and dog', 'I love my cat', 'Dogs are great']\n",
    "vector_store.add_texts(data)\n",
    "## Perform a similarity search. Search for the \n",
    "response = vector_store.similarity_search('What does cat and dogs have in common', k=1)\n",
    "## Display the content of the first response\n",
    "response[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "060ef994",
   "metadata": {},
   "outputs": [],
   "source": [
    "## uuid4 is used to generate unique identifiers for the documents\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "\n",
    "## Generating unique identifiers for each document\n",
    "## This is important for FAISS to keep track of the documents.\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e1fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a6c6d81f-5c95-492d-89c0-763c3f4f2d86',\n",
       " '9965042e-9324-4db5-be04-e88c6149e3c7',\n",
       " '58286f76-23af-4aba-85a5-ffe071d90580',\n",
       " 'c58446fe-0132-4da5-b796-fb03e74baafc',\n",
       " '0784b69b-3a60-4e69-835d-0066cb75e31d',\n",
       " '9d5f7884-7b84-4b2c-9975-c503ebaa3437',\n",
       " '5150d679-ab6e-41b9-ae41-cb9aa238da46',\n",
       " 'e38ac633-d312-42eb-8646-f91066386ffb',\n",
       " '4bde7fba-f441-4ff6-bb83-d0b2a6de62c0',\n",
       " '94ebdeba-7cdf-439e-af24-3a2cd56f4c2d']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define a new FAISS index with dot product similarity\n",
    "import faiss\n",
    "index = faiss.IndexFlatIP(768)\n",
    "\n",
    "## Create a new FAISS vector store with the new index\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "## Add the documents to the FAISS vector store\n",
    "## This will index the documents and make them searchable.\n",
    "vector_store.add_documents(documents,ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b628fa",
   "metadata": {},
   "source": [
    "##### Quering Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29407adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='58286f76-23af-4aba-85a5-ffe071d90580', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(id='e38ac633-d312-42eb-8646-f91066386ffb', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Perform a similarity search\n",
    "## This will return the top k most similar documents to the query.\n",
    "vector_store.similarity_search(\"LangChain provides abstractions to make working with LLMs easy\",k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e954139",
   "metadata": {},
   "source": [
    "Performing Similarity Search with filters on metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e924dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Building an exciting new project with LangChain - come check it out!-[{'source': 'tweet'}]\n",
      "-LangGraph is the best framework for building stateful, agentic applications!-[{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "## Query directly with the vector store\n",
    "## We can use the filter parameter to filter the results based on metadata.\n",
    "results = vector_store.similarity_search(\n",
    "    'Langchain provides abstractions to make workings with LLMs easy',\n",
    "    k=2,\n",
    "    filter={'source':'tweet'}\n",
    ")\n",
    "\n",
    "## Display the results\n",
    "for res in results:\n",
    "    print(f'-{res.page_content}-[{res.metadata}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6386d",
   "metadata": {},
   "source": [
    "We can apply advance metadata filters for doing the same similarity search. The current list of supported operators are:\n",
    "\n",
    "\n",
    "    $eq (equals)\n",
    "    $neq (not equals)\n",
    "    $gt (greater than)\n",
    "    $lt (less than)\n",
    "    $gte (greater than or equal)\n",
    "    $lte (less than or equal)\n",
    "    $in (membership in list)\n",
    "    $nin (not in list)\n",
    "    $and (all conditions must match)\n",
    "    $or (any condition must match)\n",
    "    $not (negation of condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0818d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Robbers broke into the city bank and stole $1 million in cash.-[{'source': 'news'}]\n",
      "-The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.-[{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "## Using advance metadata filtering for doing the same similarity search\n",
    "results = vector_store.similarity_search(\n",
    "    'Langchain provides abstractions to make workings with LLMs easy',\n",
    "    k=2,\n",
    "    filter={'source':{'$eq':'news'}}\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f'-{res.page_content}-[{res.metadata}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f3621",
   "metadata": {},
   "source": [
    "We can also get the similarity score for each results which we are getting using **similarity_search_with_score()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0773773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*[Score=0.3349035978317261] The stock market is down 500 points today due to fears of a recession.-[{'source': 'news'}]\n",
      "*[Score=0.0808696299791336] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.-[{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    'How is the stock market',\n",
    "    k=2,\n",
    "    filter={'source':'news'}\n",
    ")\n",
    "\n",
    "for res,scr in results:\n",
    "    print(f'*[Score={scr}] {res.page_content}-[{res.metadata}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518bd2f",
   "metadata": {},
   "source": [
    "##### Retriever\n",
    "We can also convert our vector store into a retriever for easy usage in our chains. This is how we will use it in RAG applications.\n",
    "\n",
    "There are three different type of search_type we can select from:\n",
    "- Similarity,\n",
    "- Maximum Marginal Relevance (MMR)\n",
    "- Similarity Score Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5373a3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c58446fe-0132-4da5-b796-fb03e74baafc', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type = 'mmr',search_kwargs={'k':1})\n",
    "retriever.invoke('Stealing from the bank is crime', filter={'source':'news'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd0d61",
   "metadata": {},
   "source": [
    "#### Saving and Loading \n",
    "\n",
    "Till now we were storing in-memory, but we can also save and load the FAISS index in local. This is useful as we don't have to recreate it each time we use it.\n",
    "\n",
    "**Saving** - save_local(folder_path, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7409b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving FAISS index in local\n",
    "vector_store.save_local('faiss_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901886a6",
   "metadata": {},
   "source": [
    "**Loading** - load_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4dec19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading faiss index\n",
    "new_vectore_store = FAISS.load_local(\n",
    "    folder_path='faiss_index', \n",
    "    embeddings=embeddings, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "docs = new_vectore_store.similarity_search('qux', k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03b29956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='58286f76-23af-4aba-85a5-ffe071d90580', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "100ae745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "emb = embeddings.embed_query('This is ashu')\n",
    "len(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0ba46",
   "metadata": {},
   "source": [
    "##### Building a Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "007011af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "## loading the LLM model\n",
    "model= ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "## loading the text document\n",
    "loader = TextLoader('speech.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "## defining index\n",
    "index = faiss.IndexFlatIP(1536)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap=50, add_start_index = True)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "doc_ids = vector_store.add_documents(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d50bd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_score = vector_store.as_retriever(search_type = 'similarity_score_threshold', search_kwargs={'score_threshold':0.4})\n",
    "retriever = vector_store.as_retriever(search_type = 'mmr', search_kwargs={'k':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4992c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0e37222c-426e-41da-92af-826f8d5a28df', metadata={'source': 'speech.txt', 'start_index': 2382}, page_content='The transformation that the Northeast has seen in the last 11 years is not just about numbers—it is change that can be felt on the ground. We have not just built a connection with the Northeast through government schemes—we have built a bond from the heart. You might be surprised to hear this: ministers from our central government have visited the Northeast more than 700 times. And it wasn’t just about visiting and leaving—the rule was to stay overnight. They experienced the land, they saw the'),\n",
       " Document(id='8204108c-2697-4a6f-972e-13dde727d68a', metadata={'source': 'speech.txt', 'start_index': 12352}, page_content=\"Rising Northeast is not just an investors' summit — it is a movement. It is a call to action. The future of Bharat will rise to new heights through the bright future of the Northeast. I have complete faith in all the business leaders. Come, let us together make our Ashtalakshmi an inspiration for a ‘Viksit Bharat’. I am fully confident that today’s collective efforts, your enthusiasm, and your commitment are turning hope into belief. And I am certain that by the time we hold the second Rising\")]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('What did PM talk about transformation of the Northeast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c456a8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0e37222c-426e-41da-92af-826f8d5a28df', metadata={'source': 'speech.txt', 'start_index': 2382}, page_content='The transformation that the Northeast has seen in the last 11 years is not just about numbers—it is change that can be felt on the ground. We have not just built a connection with the Northeast through government schemes—we have built a bond from the heart. You might be surprised to hear this: ministers from our central government have visited the Northeast more than 700 times. And it wasn’t just about visiting and leaving—the rule was to stay overnight. They experienced the land, they saw the'),\n",
       " Document(id='d4efb4ba-e28d-4f68-b663-036fd64a6ca3', metadata={'source': 'speech.txt', 'start_index': 3764}, page_content='Revolution in the Northeast. For a long time, the Northeast remained neglected. But now, the Northeast is becoming a land of opportunities. We have invested hundreds of thousands of crores of rupees in connectivity infrastructure in the Northeast. If you go to Arunachal Pradesh, you’ll see infrastructure projects like the Sela Tunnel. In Assam, you’ll witness mega projects like the Bhupen Hazarika Bridge. In just one decade, we have built 11,000 kilometres of new highways in the Northeast.'),\n",
       " Document(id='f27e4be9-a094-4027-8835-1e404f321d42', metadata={'source': 'speech.txt', 'start_index': 2841}, page_content='They experienced the land, they saw the hope in people’s eyes, and they turned that trust into a development-driven policy. We did not view infrastructure as just bricks and cement—we made it a medium for emotional connection. We moved beyond the Look East policy to embrace the mantra of Act East, and today, we are seeing the results. There was a time when the Northeast was only referred to as a frontier region. Today, it is becoming the front-runner of growth.'),\n",
       " Document(id='63e03184-e27c-410c-9495-671b6b9c7697', metadata={'source': 'speech.txt', 'start_index': 1936}, page_content='Friends,\\n\\nIt is essential for Eastern Bharat to develop for the building of a ‘Viksit Bharat’ (Developed India). And the Northeast is the most important part of Eastern Bharat. For us, EAST is not just a direction—it stands for Empower, Act, Strengthen, and Transform. This is our government’s policy for Eastern Bharat. This same policy, this same priority, has brought Eastern Bharat—and our Northeast—to the centre stage of growth.\\n\\nFriends,')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_score.invoke('What did PM talk about transformation of the Northeast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0330326e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ff18e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "example = prompt.invoke(\n",
    "    {'context':'(context goes here)', 'question':'(question goes here)'}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example)==1\n",
    "print(example[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f64ce275",
   "metadata": {},
   "outputs": [],
   "source": [
    "## context(retriever),prompt(hub),model(openai),parser(langchain)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question':RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "624ce302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PM discussed the transformation of the Northeast as a significant change felt on the ground, emphasizing a deep connection and bond established through government initiatives. He highlighted the commitment of central government ministers, who have visited the region over 700 times to engage more meaningfully. The \"Rising Northeast\" initiative was described as a movement aimed at elevating the region and contributing to the broader growth of Bharat (India).'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('What did PM talk about transformation of the Northeast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd783c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
